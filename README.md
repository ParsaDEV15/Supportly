# ğŸ§  Supportly â€” AI Customer Assistant Chatbot

**Supportly** is a smart customer support assistant powered by Large Language Models (LLMs), built using **LangChain**, **RAG (Retrieval-Augmented Generation)**, and **MongoDB**. It provides accurate, real-time assistance to customers by answering FAQs, checking order status, and recommending products.

This project demonstrates how to build a production-ready AI assistant with a vector database, tool-augmented agents, and natural language interfaces.

---

## âœ¨ Features

- âœ… Natural language chatbot interface
- ğŸ” RAG-based retrieval from embedded FAQ knowledge
- ğŸ“¦ Order status lookup via MongoDB backend
- ğŸ’¡ Product recommendation support (static or future ML-based)
- ğŸ”§ Modular and extensible with LangChain tools

---

## ğŸ§± Tech Stack

- **LangChain** â€“ LLM orchestration and agent framework
- **OpenAI GPT-5-nano-2025-08-07** â€“ Language model backend
- **Chroma** â€“ Stores FAQ documents
- **MongoDB** - Stores orders and products data
- **Streamlit** â€“ Frontend
- **Python 3.12+**

---

## ğŸ“ Project Structure

```bash
supportly/
â”œâ”€â”€ app
â”‚   â”œâ”€â”€ prompts/
â”‚   â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ chatbot.py
â”‚   â”œâ”€â”€ embedding.py
â”‚   â””â”€â”€ retriever.py
â”‚
â”œâ”€â”€ config
â”œâ”€â”€ â””â”€â”€ settings.py
â”œâ”€â”€ data
â”œâ”€â”€ â””â”€â”€ data_pipeline.py
â”œâ”€â”€ db
â”‚   â”œâ”€â”€ add_products.py
â”‚   â”œâ”€â”€ create_orders.py
â”‚   â”œâ”€â”€ mongo_setup.py
â”‚   â””â”€â”€ products.json
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ streamlit_app.py
```
---

## ğŸš€ How to Use

Follow the steps below to run **Supportly** locally.

1. **Clone the repository**
```bash
git clone https://github.com/ParsaDEV15/Supportly.git
cd supportly
```

2. **Create and activate a virtual environment**
```bash
python -m venv .venv
source .venv/bin/activate        # macOS / Linux
.venv\Scripts\activate           # Windows
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
```

4. **Configure environment variables**

Create a `.env` file:
```env
OPENAI_API_KEY=your_openai_api_key
MONGODB_URI=your_mongodb_connection_string
```

5. **Set up the database**

Initialize MongoDB and populate it with sample data required by the chatbot.

```bash
python db/add_products.py
python db/create_orders.py
```

- **`db/add_products.py`**  
  Loads a predefined list of products from `products.json` and inserts them into the MongoDB products collection.  
  These products are used by the assistant to answer product-related questions and provide recommendations.

- **`db/create_orders.py`**  
  Creates and manages sample customer orders via a simple CLI interface. The script allows interactive order creation,  
  stores orders in the MongoDB orders collection, and supports viewing existing orders for testing order-status queries.


6. **Prepare the FAQ data**

First, generate and preprocess the FAQ data using the data pipeline script:

```bash
python data/data_pipeline.py
```

This step converts the raw FAQ content into a structured format suitable for embedding and retrieval.


7. **Build the vector store**

After the FAQ data is prepared, embed the documents into the vector database:

```bash
python app/embedding.py
```


This step generates vector embeddings and stores them for use in the RAG-based retrieval system.

8. **Run the application**
```bash
streamlit run streamlit_app.py
```

You can now interact with the assistant to ask FAQ-related questions, check order status, and receive product recommendations.

**Notes:**
- Ensure MongoDB is running before starting the application
- FAQ embeddings only need to be generated once unless the data changes